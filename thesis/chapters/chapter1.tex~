Hello and welcome to my thesis. I'd like to talk to you today about using computers to predict whether or not your nice drug compounds may interfere with the enzymes that people really need in order break down other drugs and foreign substances that are already inside them.

\section{Aims}
The aim of this project is to quantify the risk of off target effects for the candidate molecules after building machine learning models that make binary classification of compounds based on their structure, as inhibitors or non-inhibitors of Cytochrome P450.

\section{Background}
The goal of pharmaceutical sciences is to identify and market safe and efficacious drugs. Toxicity is a major source of attrition in drug development. Inhibition of enzymes in the cytochrome P450 superfamily is a major source of toxicity in human and animal models, because of their role in first pass metabolism. Perhaps conversely, if a compound inhibts cytochrome P450 it is likely to lead to toxic effects when first pass metabolism goes out of whack. For drug development, it would be useful to know wether a compound of interest inhibits cytochrome P450s as early as possible.

Cytochrome P450 superfamily is large and varied. Different isozymes metabolize different substrates. Even within and between individuals pharmacokinetic and pharmacodynamic variability is high for reasons not entirely characterized. Designing assays for each isozyme and SNP and running them against every compound of interest as a general stategy is potentially cost prohibitive. This project was designed to test the predictive power of computational methods for potential cytochrome P450 inhibition based on chemical structure.

Drug development costs have had an upward trend for some time and for a variety of reasons. Hopefully this approach will lower costs.\cite{Visser2014} Or rather, the foundational skills demonstrated in this thesis are needed to pursue a systems pharamalogical approach to during development that the industry has recently turned toward as a way to boost R\&D productivity.\cite{Visser2014,Berg2014} It is also part of the larger project of \textit{in silico} drug-development, in which we can reduce \textit{in vivo} and clinical drug testing and increase the number of effecive treatments for patients.

There is a tradition of associating compound structure with bioactivity that goes back at least to Hansch and has progressed under the moniker of Quantitative Structure Activity Relationship. QSAR started with direct measures of chemical compounds and then derived features and used them to then build expert systems or statistical models that tried to predict biological activity. At the same time the field of machine learning emerged using computation -- in an analogous and more general way -- to associate features with results, inputs with outputs. Machine learning can be thought of as using algorithms to figure out how to perform important tasks by generalizing from examples. These algorithms are of course usually laborious, which necessitates their execution by computer.

Statistical Learning builds upon the peer prediction of machine learning. Statistical learning also predicts but focuses more on models and methods that can be used by scientists and engineers.\cite{James2013} Further extension of the statistical learning discipline can lead to important contributions to systems pharmacology. Or rather statitical learning methods are an important precursor to the needs of systems biology and systems pharmacology modeling.

This project compares different techniques for Cytochrome P450 inhibition prediction in the framework of statistical learning. 

Reproducibility is a key focus of this investigation. As much as possible, the code and data used in this study will be made publicly available and source controlled. Reproducibility is a practice and a habit, a good one to get into. An attempt was made to make the materials and methods for this project reproducible in a completely automated way, but I have fallen short of this goal due to my own technical shortcomings and the necessary inclusion of proprietary software for crucial descriptor generation.

\section{Review of Literature}
\subsection{Cytochrome P450 superfamily}

One of the largest and most functionally diverse of superfamilies is the cytochrome P450 family of hemoproteins. From bacteria to humans, the functional breadth of cytochrome P450 activity is impressive. At last count there were well in excess of 2000 identified cytochrome P450 genomic and cDNA sequences that have been divided into a total of 265 different families.\cite{Danielson2002} CYPs appear in every kingdom from bacteria to higher eukaryotes. Multiple cytochrome P450 genes can be expressed simultaneously and the number of genes per species is highly variable with a tendency for higher eukaryotes to possess more. It is the central role that these ubiquitous proteins play as phase I enzymes in human drug metabolism that is the focus of interest by the pharmaceutical industry.
 
The cytochromes P450 (CYPs) constitute the major enzyme family capable of catalyzing the oxidative biotransformation of most drugs and other lipophilic xenobiotics and are therefore of particular relevance for clinical pharmacology.\cite{Zanger2013} (Nelson, 2004; Guengerich, 2008; Zanger et al,2008) The CYP families, classified as CYP 1-3 (based on pairwise amino acid sequence identity among individual members), are involved in phase I metabolism of human drugs and xenobiotic compounds, whereas other CYP families (CYP 4, 11, 17, 17 and 21) are involved in the metabolism of endogenous compounds such as fatty acids, steroids, eicosanoids, bile acids and fat­soluble vitamins\cite{Singh2011}

The CYP enzymes that are involved in the oxidative metabolism of drugs play a major part in the activation and elimination of therapeutic drug molecules. CYP inhibition leads to decreased elimination and/or changed metabolic pathways of their substrates, which is the major cause of adverse drug-drug interactions.\cite{Lapins2013} Adverse side effects of drug-drug interactions is an important consideration, especially during the research phase of drug discovery.\cite{Cheng2011}


One important clinical consideration for CYP450 loci is the considerable substrate overlap between enzymes of this superfamily.\cite{Bains2013} Being broadly specific with respect to their substrates, CYPs are also susceptible to inhibition by a large variety of chemical compounds. The results of a large-scale screening against five CYP isoforms identified that the majority of compounds in a typical chemical library cross­inhibited several isoforms, while only 7\% of the compounds did not inhibit any of the isoforms.\cite{Veith2009}


\subsection{Rationale for early compound profiling \textit{in silico}}

Drug discovery is a multi-parameter optimization process in which compounds are optimized for interaction with the desired target and minimal off-target activities, while imparting drug-like properties on the candidate compounds.\cite{Zlokarnik2005}

%Project teams often pursue a parallel optimization approach in which multiple scaffolds are explored along multiple axes, including potency, selectivity, physicochemical properties and absorption, distribution, metabolism, excretion and toxicity (ADME­Tox) parameters(1-6)\cite{Zlokarnik2005}

%This is to minimize the risk of making potent and target-class selective compounds in a chemical space that migt be entirely incompatible with modifications needed to address other liabilities.\cite{Zlokarnik2005}

During the last decade, techniques for high-throughput \textit{in vitro} screening of CYP inhibition were developed and implemented on a broad scale in drug discovery pipelines of pharmaceutical companies, as well as much open data has accumulated through academic research initiatives (e.g. PubChem Bioassays AID 410 and 1851)

The collected data has enabled development of structure-activity relationship models for \textit{in silico} prediction of CYP inhibition.

%Recent progress in computational methods for prediction of CYP-compound interactions need to be mentioned. 

\textit{In silico} screening has been very appealling as, with the increasing power of <sic> desktop computing screening, cost could become negligible. Virtual compounds could be screened for CYP liabilities, reducing the numbers of compounds with P450 liabilities a team would otherwise synthesize, providing additional savings.\cite{Zlokarnik2005}

%As a major advance, the crystal structures of several human CYP isozymes have been solved. These structures provide more accurate geometries of the enzymes’ active sites and should lead to better representations than previous homology models that were based on crystal structures of soluble bacterial enzymes.\cite{Zlokarnik2005}

Thus, Vasanthanathan et al. and Novotarskyi et al. and more, recently developed large-scale single target models CYP1A2 isoform, and Cheng created single target QSAR models for five CYP isoforms.\cite{Lapins2013}

These models show good predictive performances.
% but share the disadvantage that they are not implemented as publicly available services.\cite{Lapins2013}

%Another deficiency of these models (except Cheng) is the use of molecular descriptors that are calculated by commercial software packages, which does not allow implementation of the models in free, open source software.\cite{Lapins2013}

%Abstract
The ability to predict clinical safety based on chemical structures is becoming an increasingly important part of regulatory decisionmaking. QSAR models are currently used by in industry and by regulators to evaluate safety concerns and possible nonclinical effects of a drug when adequate safety data are absent or equivocal.\cite{Kruhlak2012}

QSAR models and their value in informing regulatory decision making will likely increase with the standardization of analytical approaches, more complete and reliable data collection methods, and a better understanding of toxicity mechanisms and the role of disease, comorbidities, and individual susceptibility to adverse clinical events.\cite{Kruhlak2012}

''Many high-throughput technologies are now available to detect P450 inhibitors, which should decresear the number of withdrawls of novel drugs from the market due to inhibition of major P450 isozymes. High-throughpur CYP data can be used to guide medicinal chemistry away from these interactions in an early stage and in certain cases might entirely solve the issue by targeted modification of the CYP interacting functionality, leading to a reduced dimensionality of the drug optimization process. To be generally useful, P450 inhibition screens need to be calibrated against standard methods and preferably also tested with a large set of drugs, for which human drug-drug interaction outcome is known.''\cite{Zlokarnik2005}

The drafting of ICH M7 can be viewed as setting a precedent for possible future, broader regulatory applications of QSAR modeling. ICH M7, will for the first time specify that -- under very specific conditions -- the results of QSAR computational toxicology predicitions will be considered sufficient for genotoxic contaminants of pharmaceuticals under consideration and eliminate the need for laboratory testing\cite{Kruhlak2012}


\subsection{QSAR}

Quantitative structure-activity realtionship (QSAR) modeling pertains to the construction of predictive models of biological activities as a function of structural and molecular information of a compound library.\cite{Nantasenamat2009}

The concept of QSAR has typically been used for drug discovery and development and has gained wide appliciablility for correlating molecular information with not only biological activities but also with other physiochemical properties, which has therefore been termed quantitative structure-property relationship (QSPR). Typical molecular parameters that are used to account for electronic properties, hydrophobicity, steric effects, and topology can be determined empirically through experimentation or theoretically via computational chemistry.\cite{Nantasenamat2009}

A given compilation of data sets is then subjected to data pre­processing and data modeling through the use of statistical and/or machine learning techniques.\cite{Nantasenamat2009}

%Drug discovery has often evolved from serendipitous and fortuitous findings, for example, the discovery of penicillin by Alexander Fleming in 1928 triggered the antibiotic revolution... If not by chance, such discoveries may be achieved through random systematic experimentation or chemical intuition where combinatorial libraries are synthesized and then screened for potent activities. A potentially more lucrative approach is to rationally design drugs using computer­aided tools via molecular modeling, simulation, and virtual screening for the purpose of identifying promising candidates prior to synthesis.\cite{Nantasenamat2009}

''QSAR makes it possible to predict the activities/properties of a given compound as a function of its molecular strucutre. Essentially, new and untested compounds possessing similar molecular features as compounds used in the development of QSAR/QSPR models are likewise assumed to possess similar activities/properties. Several successful models have been published over the years which encompass a wide span of biological and physicochemical properties. QSAR/QSPR has great potential for modeling and designing novel compounds with robust properties by being able to forecast physiochemical properties as a function of structural properties.''\cite{Nantasenamat2009}

''The construction of Q/Q models typically comprises of two main steps: (i) description of molecular structure and (ii) multivariate analysis for correlating molecular descriptors with observed activities/properties. A essential preliminary step in model development is data understanding. Intermediate steps that are also crucial for sucessful development of such QSAR/QSPR models include data preprocessing and statistical evaluation.''\cite{Nantasenamat2009}

The successful development of a QSAR model for safety prediction requires a sufficient amount of high-quality data, the appropriate selection of descriptors, the availability of one or more suitable statistical or mathematical models as well as an effective training and validation strategy.\cite{Kruhlak2012}


%Data understanding is equivalent or can be achieved through exploratory data analysis which often starts with simple observation of the data matrix particularly the variables (also known as attributes or fields), its corresponding data types, and the data samples (also called records). As applied to the QSAR discipline, variables represent molecular descriptors; data samples represent each unique compound; data types refer to the characteristics or the kinds of data the particular value is represented as, which is essentially qualitative or quantitative in nature. Qualitative data types are interpreted as categorical labels while quantitative data types are amenable to arithmetic operations.\cite{Nantasenamat2009}

''Molecular descriptors can be thought of as essential information of a molecule in terms of its physiochemical properties such as constitutional, electronic, geometrical, hydrophobic, lipophilicity, solubility, steric, quantum chemical, and topological descriptors. ... From a practical viewpoint, molecular descriptors are chemical information that is encoded within the molecular structures for which numerous sets of algorithms are available for such transformation.''\cite{Nantasenamat2009}

%The activities and properties that can be modeled by QSAR/QSPR are dependent variables of the QSAR model. These dependent variables are assumed to be influenced by the independent variables which are the molecular descriptors. A variety of biological and chemical properties have been modeled using the QSAR approach, such parameters are summarized as: Biological Properties Bioconcentration, biodegradation, carcinogenicity, drug metabolism and clearance, inhibitor constant, mutagenicity, permeability across blood brain barrier or skin, pharmacokinetics, receptor binding. Chemical Properties boiling point, chromatographic retention time, dielectric constant, diffusion coefficient, dissociation constant, melting point, reactivity, solubility, stability, thermodynamic properties, viscosity. \cite{Nantasenamat2009}


A QSAR model defines the mathematical relationships between deescriptors and biological activities of know molecules (1), whereas receptor binding-based efficacy prediction usually utilizes binding site characterization and molecular docking analysis to study molecular interactions between a drug and targets/receptors to predict drug efficacy based on known mechanisms of action and drug chemistry.\cite{Kruhlak2012}

The predictors used in QSAR modeling are typically less precise than the “lock and key” relationships that underpin computer­aided drug design. The basic assumptions in QSAR modeling are that similar molecules exhibit similar biological activity (2) and that the physiochemical properties and/or structural properties of a molecule can be encoded as molecular descriptors to predict the biological activity of structurally related compounds.(3,4) Because of the complex nature of toxicity, safety prediction is much more challenging than efficacy prediction. Toxicity mechanisms may be unknown or poorlycharacterized, and similar pathways and targets may be associated with different toxicities and adverse events. Toxicity prediction must also consider a number of complex interactions and the ability to find the unexpected: toxicities could result from on-target effects due to incomplete knowledge or inadequate target validation, from off-target effects mediated via unknown molecules and mechanisms, or by the contribution of a patients’ genetic ackground and comorbidities. Nevertheless, (Q)SAR models have been developed by both industry and regulatory agencies. (3,5,6)\cite{Kruhlak2012}

(Kruhlak 2012) QSAR models describe the correlation between molecular features and activity at a given end point of interest. QSAR models are typically defined as those that use statistical methods to analyze the mathematical correlations between molecular features and activity, and SAR models are those that are constructed by using human expert knowledge (“expert rule­based”). Molecular features can be in the form of simple pysiochemical properties such as logP or logarithmic acid dissociation constant (pKa), substructural fragments, or mathematical descriptors, and they can be experimentally measured of calculated values. Mathematical descriptors are chemical structural features represented in numerical form, and range from simple atom counts to the product of complex equations describing electron distribution across a molecule.\cite{Kruhlak2012}

Models can be described as global or local. Global models incorporate chemicals with a range of molecular features acting with a range of chemical pathways, whereas local models are highly focused on a single chemical class and end point. Although local models generally have much higher accuracy, their narrow domain of applicability renders them impractical in most regulatory environments where predictions need to be made for structural classes covering active pharmaceutical ingredients to metabolites, degradants, reagents, and synthetic intermediates.\cite{Kruhlak2012}

Typical QSAR involves chemical structure management, descriptor calculation, and statistical analysis that are treated as separate steps and often performed by non-integrated software packages.\cite{Lapins2013} This can lead to low throughput and even lack of possibility of performing predictions for new compounds and updating the models when new data become available depending on the workflow.

%Creating structure-activity models for one CYP isozyme at a time may be a suboptimal approach since the inhibition profiles of CYPs largely overlap. A more general technique is proteochemometrics (PCM, a modelling technology that 'Sweden' introduced to study similarities and differences in molecular interaction mechanisms of groups of related proteins.\cite{Lapins2013}

%PCM creates unified models for multiple proteins interacting with multiple ligands by correlating the interaction data to descriptors of both sets of interacting entities.\cite{Lapins2013}

%In this study they aimed to create a unified PCM model for CYPs suited for drug profiling using free, open­access software and make the model publicly available for predictions.\cite{Lapins2013}


\subsection{Machine Learning}

Machine Learning algorithms can figure out how to perform important tasks by generalizing from examples.\cite{Domingos2012}

A classifier is a system of inputs (typically) a vector of discrete and/or continuous feature values and outputs a single discrete value, the class.\cite{Domingos2012}

\subsubsection*{Learning = representation + evaluation + optimization}

\begin{itemize}
\item Representation = A classifier must be represented in some formal language that the computer can handle. Conversely, a representation for the learner is tantamount to choosing the set of classifiers that it can possibly learn. This set is called the hypothesis space.

\item Evaluation = evaluation function, objective function, scoring function - distinguishes good and bad classifiers.

\item Optimization = a method to search among classifiers in the language for the highest scoring one.\cite{Domingos2012}

\end{itemize}

Most textbooks are organized by representation, but other components are equally important.\cite{Domingos2012}

The fundamental goal of machine learning is to generalize beyond the examples in the training set -- no matter how much data we have, it is unlikely that we will see those exact examples again at test time.\cite{Domingos2012}

Everyone knows about overfitting, but it comes in many forms that are not immediately obvious. One way to understand overfitting is by decomposing generalization error into bias and variance.\cite{Domingos2012}


\subsection{Stat Learning}

Statistics is the applied science that constructs and studies techniques for data analysis (Jan de Leeuw, internet)

In short, statistical learning refers to a set of approaches for estimating a function that describes a dataset as a precursor for prediction or inference.\cite{James2013}

'There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are genereated by a given stochastic data model. The other uses algorithmic models and treats the data mechanisms as unknown'\cite{Breiman2001} And he claims that the staistical community had traditionally prefered the first view.

This is a wider view than traditionaly encountered in most applied science education where simple hypothesis testing reins supreme. Opening up the field of analysis brings a host of new considerations along with the 'curse of dimensionality' such as 'degrees of freedom of the analyst', 'black box algorithms', bias estimation and the 'no free lunch theorem'.\cite{Boulesteix2014}

\subsection{Reproducibility}

Science conducted in an open fashion confers the following benefits

\begin{itemize}

\item Reproducibility of experiments alows other researchers to use the exact methods to calculate the relations between biological data.

\item Faster development of disease models and therapeutic treatments due to the reuse of existing knowledge. Project can build upon existing results or extend the research in directions unanticipated by the original team. Results can be subject to new analysis. A second look at compounds with interesting side effects.

\item Increased quality as a result of having more researchers studying the same topic to provide a layer of assurance that errors will not propogate.

\item Long-term availability of data and code if these resources are not tied to businesses or patents, then they can be posted to multiple repositories to ensure that they are available in the future.
\cite{Prlic2012}

\end{itemize}

High profile case of inability to replicate the effectss of major cancer ddrug findings. \cite{} We don't know which drugs because the findings are not public.

Information generation can happen far faster and is much more common than data analysis and (knowledge creation...yuck) proof? in the biological sciences.

There are organizational issues to overcome. More biologists trained in quantitative and statistical methods for analyzing large data sets are needed. 

Large -omics data collections can be expensive to generate and also to manage. Efforts are often distributed and decentralized, leading to duplications of effort and lack of common standards. For pharmaceutical drug discovery researchers, the long-term commitment and infrastructure required to support these approaches is not compatible with current restructuring trends in the industry.\cite{Berg2014}

Therefore, new research findings, supporting data and methods should be made publicly available for independent verification and in order not to delay medical advances.


\subsection{In summa}
This project compares the a well accepted, commercial method of binary classification with a variety of open source implementaions of common machine learning algorithms.

%\subsubsection{Function of Cytochrome P450 in humans}
%\subsubsection{Importanceof Cytochrome P450 in pharmaceutical R\&D}
%\subsubsection{Computational models of CYPs for reseach}
%\subsubsection{Computational models use by regulatory agencies}