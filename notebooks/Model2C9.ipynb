{
 "metadata": {
  "name": "",
  "signature": "sha256:46cd047cdab64993b9a10ed7d808636b2c6c55d2aa6d10c28d3473840f1377ef"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Train/Test split already done"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from sklearn.cross_validation import train_test_split\n",
      "\n",
      "# create 80%-20% train-test split\n",
      "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5555)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twoC9_test = pd.read_csv(\"data/test2c9.csv\", index_col='SID')\n",
      "twoC9_train = pd.read_csv(\"data/training2c9.csv\", index_col='SID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twoC9_train.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>ActivityScore</th>\n",
        "      <th>apol</th>\n",
        "      <th>a_acc</th>\n",
        "      <th>a_acid</th>\n",
        "      <th>a_aro</th>\n",
        "      <th>a_base</th>\n",
        "      <th>a_count</th>\n",
        "      <th>a_don</th>\n",
        "      <th>a_heavy</th>\n",
        "      <th>a_hyd</th>\n",
        "      <th>...</th>\n",
        "      <th>vsa_acid</th>\n",
        "      <th>vsa_base</th>\n",
        "      <th>vsa_don</th>\n",
        "      <th>vsa_hyd</th>\n",
        "      <th>vsa_other</th>\n",
        "      <th>vsa_pol</th>\n",
        "      <th>Weight</th>\n",
        "      <th>weinerPath</th>\n",
        "      <th>weinerPol</th>\n",
        "      <th>zagreb</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>SID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>4247169 </th>\n",
        "      <td> 42</td>\n",
        "      <td> 61.799446</td>\n",
        "      <td> 6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 12</td>\n",
        "      <td> 0</td>\n",
        "      <td> 53</td>\n",
        "      <td> 2</td>\n",
        "      <td> 31</td>\n",
        "      <td> 18</td>\n",
        "      <td>...</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td> 0</td>\n",
        "      <td> 11.365152</td>\n",
        "      <td> 259.517090</td>\n",
        "      <td> 63.639111</td>\n",
        "      <td> 62.756004</td>\n",
        "      <td> 422.44098</td>\n",
        "      <td> 3436</td>\n",
        "      <td> 47</td>\n",
        "      <td> 160</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14744505</th>\n",
        "      <td> 23</td>\n",
        "      <td> 50.819481</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td> 15</td>\n",
        "      <td> 0</td>\n",
        "      <td> 41</td>\n",
        "      <td> 1</td>\n",
        "      <td> 24</td>\n",
        "      <td> 18</td>\n",
        "      <td>...</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td> 0</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td> 262.144440</td>\n",
        "      <td> 12.949531</td>\n",
        "      <td> 32.816418</td>\n",
        "      <td> 339.41901</td>\n",
        "      <td> 1482</td>\n",
        "      <td> 37</td>\n",
        "      <td> 130</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17409970</th>\n",
        "      <td> 44</td>\n",
        "      <td> 48.782272</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 17</td>\n",
        "      <td> 0</td>\n",
        "      <td> 39</td>\n",
        "      <td> 0</td>\n",
        "      <td> 21</td>\n",
        "      <td> 18</td>\n",
        "      <td>...</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td> 0</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td> 276.754210</td>\n",
        "      <td> 13.166624</td>\n",
        "      <td>  5.682576</td>\n",
        "      <td> 294.42200</td>\n",
        "      <td> 1043</td>\n",
        "      <td> 28</td>\n",
        "      <td> 106</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4253667 </th>\n",
        "      <td> 20</td>\n",
        "      <td> 37.195171</td>\n",
        "      <td> 4</td>\n",
        "      <td> 4</td>\n",
        "      <td> 16</td>\n",
        "      <td> 0</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 22</td>\n",
        "      <td> 10</td>\n",
        "      <td>...</td>\n",
        "      <td> 54.267685</td>\n",
        "      <td> 0</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td>  89.419365</td>\n",
        "      <td> 76.123856</td>\n",
        "      <td> 96.737106</td>\n",
        "      <td> 332.32001</td>\n",
        "      <td> 1103</td>\n",
        "      <td> 33</td>\n",
        "      <td> 116</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11110647</th>\n",
        "      <td>  0</td>\n",
        "      <td> 50.529068</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 12</td>\n",
        "      <td> 1</td>\n",
        "      <td> 40</td>\n",
        "      <td> 0</td>\n",
        "      <td> 21</td>\n",
        "      <td> 20</td>\n",
        "      <td>...</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td> 0</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td> 299.232030</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td> 316.87601</td>\n",
        "      <td>  896</td>\n",
        "      <td> 33</td>\n",
        "      <td> 110</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 187 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "          ActivityScore       apol  a_acc  a_acid  a_aro  a_base  a_count  \\\n",
        "SID                                                                         \n",
        "4247169              42  61.799446      6       0     12       0       53   \n",
        "14744505             23  50.819481      3       0     15       0       41   \n",
        "17409970             44  48.782272      1       0     17       0       39   \n",
        "4253667              20  37.195171      4       4     16       0       26   \n",
        "11110647              0  50.529068      0       0     12       1       40   \n",
        "\n",
        "          a_don  a_heavy  a_hyd  ...     vsa_acid  vsa_base    vsa_don  \\\n",
        "SID                              ...                                     \n",
        "4247169       2       31     18  ...     0.000000         0  11.365152   \n",
        "14744505      1       24     18  ...     0.000000         0   0.000000   \n",
        "17409970      0       21     18  ...     0.000000         0   0.000000   \n",
        "4253667       0       22     10  ...    54.267685         0   0.000000   \n",
        "11110647      0       21     20  ...     0.000000         0   0.000000   \n",
        "\n",
        "             vsa_hyd  vsa_other    vsa_pol     Weight  weinerPath  weinerPol  \\\n",
        "SID                                                                            \n",
        "4247169   259.517090  63.639111  62.756004  422.44098        3436         47   \n",
        "14744505  262.144440  12.949531  32.816418  339.41901        1482         37   \n",
        "17409970  276.754210  13.166624   5.682576  294.42200        1043         28   \n",
        "4253667    89.419365  76.123856  96.737106  332.32001        1103         33   \n",
        "11110647  299.232030   0.000000   0.000000  316.87601         896         33   \n",
        "\n",
        "          zagreb  \n",
        "SID               \n",
        "4247169      160  \n",
        "14744505     130  \n",
        "17409970     106  \n",
        "4253667      116  \n",
        "11110647     110  \n",
        "\n",
        "[5 rows x 187 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "col_names2C9 = twoC9_train.columns.tolist()\n",
      "\n",
      "print('Column names:')\n",
      "print(col_names2C9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Column names:\n",
        "['ActivityScore', 'apol', 'a_acc', 'a_acid', 'a_aro', 'a_base', 'a_count', 'a_don', 'a_heavy', 'a_hyd', 'a_IC', 'a_ICM', 'a_nB', 'a_nBr', 'a_nC', 'a_nCl', 'a_nF', 'a_nH', 'a_nI', 'a_nN', 'a_nO', 'a_nP', 'a_nS', 'balabanJ', 'BCUT_PEOE_0', 'BCUT_PEOE_1', 'BCUT_PEOE_2', 'BCUT_PEOE_3', 'BCUT_SLOGP_0', 'BCUT_SLOGP_1', 'BCUT_SLOGP_2', 'BCUT_SLOGP_3', 'BCUT_SMR_0', 'BCUT_SMR_1', 'BCUT_SMR_2', 'BCUT_SMR_3', 'bpol', 'b_1rotN', 'b_1rotR', 'b_ar', 'b_count', 'b_double', 'b_heavy', 'b_rotN', 'b_rotR', 'b_single', 'b_triple', 'chi0', 'chi0v', 'chi0v_C', 'chi0_C', 'chi1', 'chi1v', 'chi1v_C', 'chi1_C', 'chiral', 'chiral_u', 'density', 'diameter', 'FCharge', 'GCUT_PEOE_0', 'GCUT_PEOE_1', 'GCUT_PEOE_2', 'GCUT_PEOE_3', 'GCUT_SLOGP_0', 'GCUT_SLOGP_1', 'GCUT_SLOGP_2', 'GCUT_SLOGP_3', 'GCUT_SMR_0', 'GCUT_SMR_1', 'GCUT_SMR_2', 'GCUT_SMR_3', 'Kier1', 'Kier2', 'Kier3', 'KierA1', 'KierA2', 'KierA3', 'KierFlex', 'lip_acc', 'lip_don', 'lip_druglike', 'lip_violation', 'logP(o/w)', 'logS', 'mr', 'mutagenic', 'nmol', 'opr_brigid', 'opr_leadlike', 'opr_nring', 'opr_nrot', 'opr_violation', 'PC+', 'PC-', 'PEOE_PC+', 'PEOE_PC-', 'PEOE_RPC+', 'PEOE_RPC-', 'PEOE_VSA+0', 'PEOE_VSA+1', 'PEOE_VSA+2', 'PEOE_VSA+3', 'PEOE_VSA+4', 'PEOE_VSA+5', 'PEOE_VSA+6', 'PEOE_VSA-0', 'PEOE_VSA-1', 'PEOE_VSA-2', 'PEOE_VSA-3', 'PEOE_VSA-4', 'PEOE_VSA-5', 'PEOE_VSA-6', 'PEOE_VSA_FHYD', 'PEOE_VSA_FNEG', 'PEOE_VSA_FPNEG', 'PEOE_VSA_FPOL', 'PEOE_VSA_FPOS', 'PEOE_VSA_FPPOS', 'PEOE_VSA_HYD', 'PEOE_VSA_NEG', 'PEOE_VSA_PNEG', 'PEOE_VSA_POL', 'PEOE_VSA_POS', 'PEOE_VSA_PPOS', 'petitjean', 'petitjeanSC', 'Q_PC+', 'Q_PC-', 'Q_RPC+', 'Q_RPC-', 'Q_VSA_FHYD', 'Q_VSA_FNEG', 'Q_VSA_FPNEG', 'Q_VSA_FPOL', 'Q_VSA_FPOS', 'Q_VSA_FPPOS', 'Q_VSA_HYD', 'Q_VSA_NEG', 'Q_VSA_PNEG', 'Q_VSA_POL', 'Q_VSA_POS', 'Q_VSA_PPOS', 'radius', 'reactive', 'rings', 'RPC+', 'RPC-', 'rsynth', 'SlogP', 'SlogP_VSA0', 'SlogP_VSA1', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'SMR', 'SMR_VSA0', 'SMR_VSA1', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'TPSA', 'VAdjEq', 'VAdjMa', 'VDistEq', 'VDistMa', 'vdw_area', 'vdw_vol', 'vsa_acc', 'vsa_acid', 'vsa_base', 'vsa_don', 'vsa_hyd', 'vsa_other', 'vsa_pol', 'Weight', 'weinerPath', 'weinerPol', 'zagreb']\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Isolate response variable\n",
      "ActivityScore = twoC9_train['ActivityScore']\n",
      "y_train = np.where(ActivityScore >= 40,1,0)\n",
      "\n",
      "ActivityScore2 = twoC9_test['ActivityScore']\n",
      "y_test = np.where(ActivityScore2 >= 40,1,0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# looks right sized\n",
      "y_train.shape, y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "((6593,), (1649,))"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array([0, 1, 0, ..., 1, 1, 0])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We don't need this column anymore\n",
      "to_drop = ['ActivityScore']\n",
      "inhib_feat_space = twoC9_train.drop(to_drop,axis=1)\n",
      "inhib_feat_space_test = twoC9_test.drop(to_drop,axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pull out features for future use\n",
      "features = inhib_feat_space.columns\n",
      "features_test = inhib_feat_space_test.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = inhib_feat_space.as_matrix().astype(np.float)\n",
      "X_test = inhib_feat_space_test.as_matrix().astype(np.float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape, X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "((6593, 186), (1649, 186))"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_pos1 = y_test.sum()\n",
      "n_pos1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "855"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_pos2 = y_train.sum()\n",
      "n_pos2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "3266"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Feature space holds '+repr(X_train.shape[0])+' observations and '+repr(X_test.shape[1])+' features')\n",
      "print('Unique target labels: '+repr(np.unique(y_train)))\n",
      "\n",
      "print('Feature space holds '+repr(X_test.shape[0])+' observations and '+repr(X_test.shape[1])+' features')\n",
      "print('Unique target labels: '+repr(np.unique(y_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature space holds 6593 observations and 186 features\n",
        "Unique target labels: array([0, 1])\n",
        "Feature space holds 1649 observations and 186 features\n",
        "Unique target labels: array([0, 1])\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "186"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scale the features before training model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is important\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "scaler = StandardScaler()\n",
      "X_train = scaler.fit_transform(X_train)\n",
      "X_test = scaler.fit_transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "def run_cv(X,y,clf_class,**kwargs):\n",
      "    # Construct a kfolds object\n",
      "    kf = KFold(len(y),n_folds=5,shuffle=True)\n",
      "    y_pred = y.copy()\n",
      "    \n",
      "    # Iterate through folds\n",
      "    for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train = y[train_index]\n",
      "        # Initialize a classifier with key word arguments\n",
      "        clf = clf_class(**kwargs)\n",
      "        clf.fit(X_train,y_train)\n",
      "        y_pred[test_index] = clf.predict(X_test)\n",
      "    return y_pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "from sklearn.ensemble import RandomForestClassifier as RF\n",
      "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
      "\n",
      "def accuracy(y_true,y_pred):\n",
      "    # NumPy interpretes True and False as 1. and 0.\n",
      "    return np.mean(y_true == y_pred)\n",
      "\n",
      "print(\"K-nearest-neighbors (training set):\")\n",
      "print(\"%.3f\" % accuracy(y_train, run_cv(X_train,y_train,KNN)))\n",
      "print(\"K-nearest-neighbors (test set):\")\n",
      "print(\"%.3f\" % accuracy(y_test, run_cv(X_test,y_test,KNN)))\n",
      "print('Support vector machines (training set):')\n",
      "print(\"%.3f\" % accuracy(y_train, run_cv(X_train,y_train,SVC)))\n",
      "print('Support vector machines (test set):')\n",
      "print(\"%.3f\" % accuracy(y_test, run_cv(X_test,y_test,SVC)))\n",
      "print(\"Random forest (training set):\")\n",
      "print(\"%.3f\" % accuracy(y_train, run_cv(X_train,y_train,RF)))\n",
      "print(\"Random forest (test set):\")\n",
      "print(\"%.3f\" % accuracy(y_test, run_cv(X_test,y_test,RF)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K-nearest-neighbors (training set):\n",
        "0.721"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "K-nearest-neighbors (test set):\n",
        "0.692"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Support vector machines (training set):\n",
        "0.749"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Support vector machines (test set):\n",
        "0.720"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Random forest (training set):\n",
        "0.717"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Random forest (test set):\n",
        "0.687"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "y_train = np.array(y_train)\n",
      "class_names = np.unique(y_train)\n",
      "\n",
      "confusion_matrices_training = [\n",
      "    ( \"K-Nearest-Neighbors training\", confusion_matrix(y_train,run_cv(X_train,y_train,KNN)) ),\n",
      "    ( \"Support Vector Machines training\", confusion_matrix(y_train,run_cv(X_train,y_train,SVC)) ),\n",
      "    ( \"Random Forest taining\", confusion_matrix(y_train,run_cv(X_train,y_train,RF)) ),\n",
      "]\n",
      "\n",
      "y_test = np.array(y_test)\n",
      "class_names = np.unique(y_test)\n",
      "\n",
      "confusion_matrices_test = [\n",
      "    ( \"K-Nearest-Neighbors test\", confusion_matrix(y_test,run_cv(X_test,y_test,KNN)) ),\n",
      "    ( \"Support Vector Machines test\", confusion_matrix(y_test,run_cv(X_test,y_test,SVC)) ),\n",
      "    ( \"Random Forest test\", confusion_matrix(y_test,run_cv(X_test,y_test,RF)) ),\n",
      "]\n",
      "\n",
      "#draw_confusion_matrices(confusion_matrices,class_names)\n",
      "confusion_matrices_training, confusion_matrices_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n",
        "/home/ubuntu/miniconda3/lib/python3.3/site-packages/sklearn/svm/base.py:233: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  max_iter=self.max_iter, random_seed=random_seed)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "([('K-Nearest-Neighbors training', array([[2353,  974],\n",
        "          [ 846, 2420]])),\n",
        "  ('Support Vector Machines training', array([[2351,  976],\n",
        "          [ 667, 2599]])),\n",
        "  ('Random Forest taining', array([[2513,  814],\n",
        "          [1038, 2228]]))],\n",
        " [('K-Nearest-Neighbors test', array([[528, 266],\n",
        "          [243, 612]])), ('Support Vector Machines test', array([[506, 288],\n",
        "          [167, 688]])), ('Random Forest test', array([[584, 210],\n",
        "          [285, 570]]))])"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_prob_cv(X, y, clf_class, **kwargs):\n",
      "    kf = KFold(len(y), n_folds=5, shuffle=True)\n",
      "    y_prob = np.zeros((len(y),2))\n",
      "    for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train = y[train_index]\n",
      "        clf = clf_class(**kwargs)\n",
      "        clf.fit(X_train,y_train)\n",
      "        # Predict probabilities, not classes\n",
      "        y_prob[test_index] = clf.predict_proba(X_test)\n",
      "    return y_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "# Use 10 estimators so predictions are all multiples of 0.1\n",
      "pred_prob = run_prob_cv(X_train, y_train, RF, n_estimators=10)\n",
      "pred_churn = pred_prob[:,1]\n",
      "is_churn = y_train == 1\n",
      "\n",
      "# Number of times a predicted probability is assigned to an observation\n",
      "counts = pd.value_counts(pred_churn)\n",
      "\n",
      "# calculate true probabilities\n",
      "true_prob = {}\n",
      "for prob in counts.index:\n",
      "    true_prob[prob] = np.mean(is_churn[pred_churn == prob])\n",
      "    true_prob = pd.Series(true_prob)\n",
      "\n",
      "# pandas-fu\n",
      "counts = pd.concat([counts,true_prob], axis=1).reset_index()\n",
      "counts.columns = ['pred_prob', 'count', 'true_prob']\n",
      "counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>pred_prob</th>\n",
        "      <th>count</th>\n",
        "      <th>true_prob</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0.700000</td>\n",
        "      <td> 739</td>\n",
        "      <td> 0.719892</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0.800000</td>\n",
        "      <td> 696</td>\n",
        "      <td> 0.757184</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 0.600000</td>\n",
        "      <td> 679</td>\n",
        "      <td> 0.615611</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 656</td>\n",
        "      <td> 0.535061</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0.400000</td>\n",
        "      <td> 621</td>\n",
        "      <td> 0.402576</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0.100000</td>\n",
        "      <td> 595</td>\n",
        "      <td> 0.136134</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 0.200000</td>\n",
        "      <td> 587</td>\n",
        "      <td> 0.204429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 0.300000</td>\n",
        "      <td> 552</td>\n",
        "      <td> 0.331522</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 0.900000</td>\n",
        "      <td> 533</td>\n",
        "      <td> 0.803002</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 481</td>\n",
        "      <td> 0.089397</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 317</td>\n",
        "      <td> 0.902208</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 0.450000</td>\n",
        "      <td>   8</td>\n",
        "      <td> 0.250000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 0.350000</td>\n",
        "      <td>   7</td>\n",
        "      <td> 0.285714</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 0.150000</td>\n",
        "      <td>   7</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 0.266667</td>\n",
        "      <td>   6</td>\n",
        "      <td> 0.166667</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 0.133333</td>\n",
        "      <td>   6</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 0.325000</td>\n",
        "      <td>   5</td>\n",
        "      <td> 0.200000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> 0.033333</td>\n",
        "      <td>   5</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> 0.166667</td>\n",
        "      <td>   5</td>\n",
        "      <td> 0.200000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> 0.750000</td>\n",
        "      <td>   5</td>\n",
        "      <td> 0.800000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td> 0.561538</td>\n",
        "      <td>   4</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td> 0.550000</td>\n",
        "      <td>   4</td>\n",
        "      <td> 0.250000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td> 0.702570</td>\n",
        "      <td>   3</td>\n",
        "      <td> 0.666667</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td> 0.766667</td>\n",
        "      <td>   3</td>\n",
        "      <td> 0.666667</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td> 0.250000</td>\n",
        "      <td>   3</td>\n",
        "      <td> 0.333333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td> 0.533333</td>\n",
        "      <td>   3</td>\n",
        "      <td> 0.666667</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td> 0.233333</td>\n",
        "      <td>   3</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td> 0.566667</td>\n",
        "      <td>   3</td>\n",
        "      <td> 0.333333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td> 0.633333</td>\n",
        "      <td>   2</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td> 0.050000</td>\n",
        "      <td>   2</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td> 0.833333</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td> 0.333333</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48</th>\n",
        "      <td> 0.216667</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td> 0.160000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50</th>\n",
        "      <td> 0.125000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>51</th>\n",
        "      <td> 0.875000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>52</th>\n",
        "      <td> 0.080000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>53</th>\n",
        "      <td> 0.687500</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>54</th>\n",
        "      <td> 0.440000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>55</th>\n",
        "      <td> 0.671429</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>56</th>\n",
        "      <td> 0.866667</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>57</th>\n",
        "      <td> 0.300833</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>58</th>\n",
        "      <td> 0.766667</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>59</th>\n",
        "      <td> 0.614286</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>60</th>\n",
        "      <td> 0.075000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>61</th>\n",
        "      <td> 0.420000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>62</th>\n",
        "      <td> 0.233333</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>63</th>\n",
        "      <td> 0.320000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>64</th>\n",
        "      <td> 0.840000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>65</th>\n",
        "      <td> 0.270000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66</th>\n",
        "      <td> 0.216667</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>67</th>\n",
        "      <td> 0.558333</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>68</th>\n",
        "      <td> 0.387500</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>69</th>\n",
        "      <td> 0.028571</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>70</th>\n",
        "      <td> 0.025000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>71</th>\n",
        "      <td> 0.385000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>72</th>\n",
        "      <td> 0.620000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>73</th>\n",
        "      <td> 0.083333</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>74</th>\n",
        "      <td> 0.487500</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75</th>\n",
        "      <td> 0.925000</td>\n",
        "      <td>   1</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>76 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "    pred_prob  count  true_prob\n",
        "0    0.700000    739   0.719892\n",
        "1    0.800000    696   0.757184\n",
        "2    0.600000    679   0.615611\n",
        "3    0.500000    656   0.535061\n",
        "4    0.400000    621   0.402576\n",
        "5    0.100000    595   0.136134\n",
        "6    0.200000    587   0.204429\n",
        "7    0.300000    552   0.331522\n",
        "8    0.900000    533   0.803002\n",
        "9    0.000000    481   0.089397\n",
        "10   1.000000    317   0.902208\n",
        "11   0.450000      8   0.250000\n",
        "12   0.350000      7   0.285714\n",
        "13   0.150000      7   0.000000\n",
        "14   0.266667      6   0.166667\n",
        "15   0.133333      6   0.000000\n",
        "16   0.325000      5   0.200000\n",
        "17   0.033333      5   0.000000\n",
        "18   0.166667      5   0.200000\n",
        "19   0.750000      5   0.800000\n",
        "20   0.561538      4   1.000000\n",
        "21   0.550000      4   0.250000\n",
        "22   0.702570      3   0.666667\n",
        "23   0.766667      3   0.666667\n",
        "24   0.250000      3   0.333333\n",
        "25   0.533333      3   0.666667\n",
        "26   0.233333      3   0.000000\n",
        "27   0.566667      3   0.333333\n",
        "28   0.633333      2   0.500000\n",
        "29   0.050000      2   0.000000\n",
        "..        ...    ...        ...\n",
        "46   0.833333      1   1.000000\n",
        "47   0.333333      1   0.000000\n",
        "48   0.216667      1   0.000000\n",
        "49   0.160000      1   0.000000\n",
        "50   0.125000      1   0.000000\n",
        "51   0.875000      1   1.000000\n",
        "52   0.080000      1   0.000000\n",
        "53   0.687500      1   0.000000\n",
        "54   0.440000      1   1.000000\n",
        "55   0.671429      1   1.000000\n",
        "56   0.866667      1   1.000000\n",
        "57   0.300833      1   0.000000\n",
        "58   0.766667      1   0.000000\n",
        "59   0.614286      1   1.000000\n",
        "60   0.075000      1   0.000000\n",
        "61   0.420000      1   0.000000\n",
        "62   0.233333      1   0.000000\n",
        "63   0.320000      1   1.000000\n",
        "64   0.840000      1   1.000000\n",
        "65   0.270000      1   0.000000\n",
        "66   0.216667      1   0.000000\n",
        "67   0.558333      1   1.000000\n",
        "68   0.387500      1   1.000000\n",
        "69   0.028571      1   0.000000\n",
        "70   0.025000      1   0.000000\n",
        "71   0.385000      1   0.000000\n",
        "72   0.620000      1   1.000000\n",
        "73   0.083333      1   0.000000\n",
        "74   0.487500      1   0.000000\n",
        "75   0.925000      1   1.000000\n",
        "\n",
        "[76 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ggplot import *\n",
      "%matplotlib inline\n",
      "\n",
      "baseline = np.mean(is_churn)\n",
      "ggplot(counts,aes(x='pred_prob',y='true_prob',size='count')) + \\\n",
      "    geom_point(color='blue') + \\\n",
      "    stat_function(fun = lambda x: x, color='red') + \\\n",
      "    stat_function(fun = lambda x: baseline, color='green') + \\\n",
      "    xlim(-0.05,  1.05) + ylim(-0.05,1.05) + \\\n",
      "    ggtitle(\"Classificatio by Random Forests\") + \\\n",
      "    xlab(\"Predicted probability\") + ylab(\"Relative frequency of outcome\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAH+CAYAAAD6aPjSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f1e1ee4d810>"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "<ggplot: (8735455524053)>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "roc_auc_score(is_churn, pred_churn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0.79312145924777"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([[ 0.3,  0.7],\n",
        "       [ 0.2,  0.8],\n",
        "       [ 0.1,  0.9],\n",
        "       ..., \n",
        "       [ 0.2,  0.8],\n",
        "       [ 0.3,  0.7],\n",
        "       [ 0.9,  0.1]])"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}